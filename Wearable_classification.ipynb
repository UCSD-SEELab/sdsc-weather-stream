{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out = pd.read_excel('Data_Folder/4_12_outsided_wearable.xlsx',header=0,index_col=0)\n",
    "In = pd.read_excel('Data_Folder/Demo4_20/4_20_wearable_inside.xlsx',header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "In = In.resample('1T',on='#VALUE!').mean()\n",
    "Out = Out.fillna(method='ffill')\n",
    "In = In.fillna(method='ffill')\n",
    "Out = Out.resample('1T',on='time').mean()\n",
    "Out.drop(columns=['Time(s)'], inplace=True)\n",
    "In.drop(columns=['Time(s)'], inplace=True)\n",
    "Out.index = range(Out.shape[0])\n",
    "In.index = range(In.shape[0])\n",
    "In = In.iloc[:500,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "In_label = np.ones((In.shape[0],), dtype=int)\n",
    "Out_label = np.zeros((Out.shape[0],), dtype=int)\n",
    "In['label'] = In_label\n",
    "Out['label'] = Out_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.concat([In,Out],axis=0)\n",
    "DF = shuffle(DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC, NuSVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(DF.iloc[:,:6], DF.iloc[:,6:], test_size = 0.2, random_state = 0)\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[198   0]\n",
      " [  0 102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       198\n",
      "           1       1.00      1.00      1.00       102\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[197   1]\n",
      " [  0 102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       198\n",
      "           1       0.99      1.00      1.00       102\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier2 = svm.SVC(kernel='poly',degree=2)\n",
    "classifier2.fit(X_train,y_train)\n",
    "y_pred = classifier2.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"the result is not good as the previous two\"\"\"\n",
    "classifier3 = svm.SVC(kernel='rbf')\n",
    "classifier3.fit(X_train,y_train)\n",
    "y_pred = classifier3.predict(X_test)\n",
    "\n",
    "#print(confusion_matrix(y_test,y_pred))  \n",
    "#print(classification_report(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''the result is not good as the previous two'''\n",
    "classifier4 = svm.SVC(kernel='sigmoid')\n",
    "classifier4.fit(X_train,y_train)\n",
    "y_pred = classifier4.predict(X_test)\n",
    "\n",
    "#print(confusion_matrix(y_test,y_pred))  \n",
    "#print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed = pd.read_csv('Data_Folder/Demo3_5/Wearable_label.csv')\n",
    "mixed.dropna(inplace=True)\n",
    "mixed = shuffle(mixed)\n",
    "mixed.drop(columns=['time'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  5]\n",
      " [15 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.55      0.37        11\n",
      "         1.0       0.85      0.66      0.74        44\n",
      "\n",
      "   micro avg       0.64      0.64      0.64        55\n",
      "   macro avg       0.57      0.60      0.56        55\n",
      "weighted avg       0.74      0.64      0.67        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(mixed.iloc[:,:6])\n",
    "y_test_mixed = mixed.iloc[:,6:]\n",
    "print(confusion_matrix(y_test_mixed,y_pred))  \n",
    "print(classification_report(y_test_mixed,y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  5]\n",
      " [27 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.18      0.55      0.27        11\n",
      "         1.0       0.77      0.39      0.52        44\n",
      "\n",
      "   micro avg       0.42      0.42      0.42        55\n",
      "   macro avg       0.48      0.47      0.39        55\n",
      "weighted avg       0.65      0.42      0.47        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier2.predict(mixed.iloc[:,:6])\n",
    "y_test_mixed = mixed.iloc[:,6:]\n",
    "print(confusion_matrix(y_test_mixed,y_pred))  \n",
    "print(classification_report(y_test_mixed,y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1199 samples, validate on 300 samples\n",
      "Epoch 1/50\n",
      "1199/1199 [==============================] - 1s 485us/step - loss: 1.3152 - acc: 0.9174 - val_loss: 1.1705 - val_acc: 0.9267\n",
      "Epoch 2/50\n",
      "1199/1199 [==============================] - 0s 161us/step - loss: 1.1036 - acc: 0.9308 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 3/50\n",
      "1199/1199 [==============================] - 0s 166us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 4/50\n",
      "1199/1199 [==============================] - 0s 154us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 5/50\n",
      "1199/1199 [==============================] - 0s 156us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 6/50\n",
      "1199/1199 [==============================] - 0s 155us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 7/50\n",
      "1199/1199 [==============================] - 0s 175us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 8/50\n",
      "1199/1199 [==============================] - 0s 182us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 9/50\n",
      "1199/1199 [==============================] - 0s 152us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 10/50\n",
      "1199/1199 [==============================] - 0s 164us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 11/50\n",
      "1199/1199 [==============================] - 0s 158us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 12/50\n",
      "1199/1199 [==============================] - 0s 169us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 13/50\n",
      "1199/1199 [==============================] - 0s 161us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 14/50\n",
      "1199/1199 [==============================] - 0s 163us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 15/50\n",
      "1199/1199 [==============================] - 0s 172us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 16/50\n",
      "1199/1199 [==============================] - 0s 163us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 17/50\n",
      "1199/1199 [==============================] - 0s 171us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 18/50\n",
      "1199/1199 [==============================] - 0s 166us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 19/50\n",
      "1199/1199 [==============================] - 0s 184us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 20/50\n",
      "1199/1199 [==============================] - 0s 165us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 21/50\n",
      "1199/1199 [==============================] - 0s 184us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 22/50\n",
      "1199/1199 [==============================] - 0s 179us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 23/50\n",
      "1199/1199 [==============================] - 0s 154us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 24/50\n",
      "1199/1199 [==============================] - 0s 175us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 25/50\n",
      "1199/1199 [==============================] - 0s 160us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 26/50\n",
      "1199/1199 [==============================] - 0s 229us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 27/50\n",
      "1199/1199 [==============================] - 0s 174us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 28/50\n",
      "1199/1199 [==============================] - 0s 170us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 29/50\n",
      "1199/1199 [==============================] - 0s 172us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 30/50\n",
      "1199/1199 [==============================] - 0s 211us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 31/50\n",
      "1199/1199 [==============================] - 0s 161us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 32/50\n",
      "1199/1199 [==============================] - 0s 184us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 33/50\n",
      "1199/1199 [==============================] - 0s 177us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 34/50\n",
      "1199/1199 [==============================] - 0s 163us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 35/50\n",
      "1199/1199 [==============================] - 0s 182us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 36/50\n",
      "1199/1199 [==============================] - 0s 214us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 37/50\n",
      "1199/1199 [==============================] - 0s 176us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 38/50\n",
      "1199/1199 [==============================] - 0s 228us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 39/50\n",
      "1199/1199 [==============================] - 0s 174us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 40/50\n",
      "1199/1199 [==============================] - 0s 173us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 41/50\n",
      "1199/1199 [==============================] - 0s 175us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 42/50\n",
      "1199/1199 [==============================] - 0s 175us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 43/50\n",
      "1199/1199 [==============================] - 0s 162us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 44/50\n",
      "1199/1199 [==============================] - 0s 181us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 45/50\n",
      "1199/1199 [==============================] - 0s 169us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 46/50\n",
      "1199/1199 [==============================] - 0s 155us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 47/50\n",
      "1199/1199 [==============================] - 0s 195us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 48/50\n",
      "1199/1199 [==============================] - 0s 165us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 49/50\n",
      "1199/1199 [==============================] - 0s 167us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "Epoch 50/50\n",
      "1199/1199 [==============================] - 0s 183us/step - loss: 1.0903 - acc: 0.9316 - val_loss: 1.1691 - val_acc: 0.9267\n",
      "300/300 [==============================] - 0s 65us/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(60, input_dim=6, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,validation_data=(X_test,y_test), batch_size = 10, epochs = 50)\n",
    "scores = model.evaluate(X_test,y_test,batch_size = 10)\n",
    "#print(confusion_matrix(y_test,y_pred))  \n",
    "#print(classification_report(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1691122824239715, 0.9266666571299235]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
